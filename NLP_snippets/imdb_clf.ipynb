{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "HWW7dg7i3itT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.13.0-rc0'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fetch the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "80BSXvnV3itU",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metal device set to: Apple M1\n",
            "\n",
            "systemMemory: 16.00 GB\n",
            "maxCacheSize: 5.33 GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-01 12:19:37.069886: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-07-01 12:19:37.070512: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "data, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLL8boO13itU",
        "outputId": "f8dd96ff-c40e-4a4f-be58-ca1539bfaa2a",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train': <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>, 'test': <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>, 'unsupervised': <_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>}\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split the data into traingin and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9PZpgJh3itU",
        "outputId": "46458c77-d13e-403e-dc27-3063568624df",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "train_data, test_data = data['train'], data['test']\n",
        "print(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jDOoOPEx3itV",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def parse_review(dataset):\n",
        "    reviews = []\n",
        "    labels = []\n",
        "\n",
        "    for review, label in dataset:\n",
        "        reviews.append(review.numpy().decode('utf8'))\n",
        "        labels.append(label.numpy())\n",
        "    return reviews, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z7T4BkJG3itV",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-01 12:19:39.336136: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
            "\t [[{{node Placeholder/_4}}]]\n",
            "2023-07-01 12:19:39.336488: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_2}}]]\n",
            "2023-07-01 12:19:40.608334: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
            "\t [[{{node Placeholder/_1}}]]\n",
            "2023-07-01 12:19:40.608555: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
            "\t [[{{node Placeholder/_4}}]]\n"
          ]
        }
      ],
      "source": [
        "train_review, train_label = parse_review(train_data)\n",
        "test_review, test_label = parse_review(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QiUJUoA3itV",
        "outputId": "9be9e198-d946-4c28-873d-935f6b80a5ed",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25000 25000\n",
            "25000 25000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_review), len(train_label))\n",
        "print(len(test_review), len(test_label))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenize words and padthem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xO60S8R13itV",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "numwords = 20000\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=numwords, oov_token='<OOV>')\n",
        "pad = tf.keras.preprocessing.sequence.pad_sequences\n",
        "\n",
        "tokenizer.fit_on_texts(train_review)\n",
        "\n",
        "train_seq = tokenizer.texts_to_sequences(train_review)\n",
        "test_seq = tokenizer.texts_to_sequences(test_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RJKN44J33itW",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "mx_len = 0\n",
        "for i in train_seq:\n",
        "    mx_len = max(mx_len, len(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE11y5PG3itW",
        "outputId": "1b80fa66-9c9e-4a43-d952-b3c701823708",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25000, 120)\n",
            "(25000, 120)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_pad = pad(train_seq, padding='post', maxlen=120, truncating='post')\n",
        "test_pad = pad(test_seq, padding='post', maxlen=120, truncating='post')\n",
        "\n",
        "print(train_pad.shape)\n",
        "print(test_pad.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfREr45U3itW",
        "outputId": "f86cb243-c381-49d8-d2d3-e51e2df22b9b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(test_label).shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SfD7aIJ03itW",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=numwords+1, output_dim=10, input_length=120),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "optim = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "model.compile(\n",
        "    loss = loss,\n",
        "    optimizer=optim,\n",
        "    metrics=['acc']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWTBfNLK3itW",
        "outputId": "f308873d-a640-42d9-d4bf-3f7d5b9b1ac4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 120, 10)           200010    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 16)                1216      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 102       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201335 (786.46 KB)\n",
            "Trainable params: 201335 (786.46 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDt79OZg3itW",
        "outputId": "d055490d-aa04-4443-ecdc-210df1c7ddbc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-01 12:21:08.361618: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-07-01 12:21:08.586596: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-07-01 12:21:08.603984: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-07-01 12:21:08.829975: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-07-01 12:21:08.854500: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - ETA: 0s - loss: 0.6930 - acc: 0.5079"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-01 12:21:14.327851: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-07-01 12:21:14.424194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-07-01 12:21:14.437070: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 8s 66ms/step - loss: 0.6930 - acc: 0.5079 - val_loss: 0.6928 - val_acc: 0.5115\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 5s 52ms/step - loss: 0.6923 - acc: 0.5345 - val_loss: 0.6920 - val_acc: 0.5265\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 5s 49ms/step - loss: 0.6904 - acc: 0.5551 - val_loss: 0.6897 - val_acc: 0.5717\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.6846 - acc: 0.6151 - val_loss: 0.6801 - val_acc: 0.6121\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.6072 - acc: 0.7163 - val_loss: 0.5296 - val_acc: 0.7633\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 5s 46ms/step - loss: 0.4396 - acc: 0.8255 - val_loss: 0.4538 - val_acc: 0.8015\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 5s 45ms/step - loss: 0.3629 - acc: 0.8653 - val_loss: 0.4323 - val_acc: 0.8113\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - 5s 52ms/step - loss: 0.3144 - acc: 0.8870 - val_loss: 0.4333 - val_acc: 0.8135\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - 5s 47ms/step - loss: 0.2791 - acc: 0.9022 - val_loss: 0.4261 - val_acc: 0.8177\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - 4s 45ms/step - loss: 0.2506 - acc: 0.9142 - val_loss: 0.4312 - val_acc: 0.8182\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 0.2268 - acc: 0.9225 - val_loss: 0.4405 - val_acc: 0.8162\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 0.2074 - acc: 0.9294 - val_loss: 0.4578 - val_acc: 0.8126\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 0.1921 - acc: 0.9346 - val_loss: 0.4536 - val_acc: 0.8169\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - 4s 45ms/step - loss: 0.1788 - acc: 0.9394 - val_loss: 0.4693 - val_acc: 0.8136\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - 4s 43ms/step - loss: 0.1674 - acc: 0.9436 - val_loss: 0.4779 - val_acc: 0.8138\n"
          ]
        }
      ],
      "source": [
        "train_label_mdl = np.array(train_label,dtype=np.float32)\n",
        "test_label_mdl = np.array(test_label,dtype=np.float32)\n",
        "history = model.fit(\n",
        "    train_pad,\n",
        "    train_label_mdl,\n",
        "    epochs=15,\n",
        "    batch_size=250,\n",
        "    validation_data=(test_pad, test_label_mdl)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J6CD9Pn3itX",
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvLmt2ip3itX",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
